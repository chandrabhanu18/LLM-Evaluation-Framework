[tool.poetry]
name = "llm-eval"
version = "0.1.0"
description = "Production-grade LLM evaluation framework"
authors = ["Your Name <you@example.com>"]
license = "MIT"
readme = "README.md"
homepage = "https://example.com/llm-eval"
repository = "https://github.com/your-org/llm-eval"
keywords = ["llm", "evaluation", "nlp", "metrics", "rag"]
classifiers = [
	"Programming Language :: Python :: 3",
	"Programming Language :: Python :: 3 :: Only",
	"License :: OSI Approved :: MIT License",
	"Intended Audience :: Developers",
	"Topic :: Scientific/Engineering :: Artificial Intelligence",
]

[tool.poetry.dependencies]
python = ">=3.10,<4.0"
typer = "^0.9"
pydantic = "^1.10"
pandas = "^2.0"
numpy = "^1.24"
sentence-transformers = "^2.2"
rouge-score = "^0.1.2"
sacrebleu = "^2.3.1"
matplotlib = "^3.7"
pyyaml = "^6.0"
requests = "^2.31"
openai = "^1.0"

[tool.poetry.scripts]
llm-eval = "llm_eval.cli:app"

[tool.poetry.dev-dependencies]
pytest = "^7.0"
pytest-cov = "^4.0"
build = "^1.0"

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"
